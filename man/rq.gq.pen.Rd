% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/gqPen.R
\name{rq.gq.pen}
\alias{rq.gq.pen}
\title{Title Quantile regression estimation and consistent variable selection across multiple quantiles}
\usage{
rq.gq.pen(
  x,
  y,
  tau,
  lambda = NULL,
  weights = NULL,
  penalty.factor = NULL,
  tau.penalty.factor = NULL,
  gmma = 0.2,
  maxIter = 200,
  lambda.discard = TRUE,
  epsilon = 1e-04,
  beta0 = NULL
)
}
\arguments{
\item{x}{covariate matrix}

\item{y}{a univariate response variable}

\item{tau}{a sequence of quantiles to be modeled}

\item{lambda}{shrinkage parameter. Default is NULL, and the algorithm provides a solution path.}

\item{weights}{observation weights. Default is NULL, which means equal weights.}

\item{penalty.factor}{weights for the shrinkage parameter for each covariate. Default is equal weight.}

\item{tau.penalty.factor}{weights for different quantiles. Default is equal weight.}

\item{gmma}{tuning parameter for the Huber loss}

\item{maxIter}{maximum number of iteration. Default is 200.}

\item{lambda.discard}{Default is TRUE, meaning that the solution path stops if the relative deviance changes sufficiently small. It usually happens near the end of solution path. However, the program returns at least 70 models along the solution path.}

\item{epsilon}{The epsilon level convergence. Default is 1e-4.}

\item{beta0}{Initial estimates. Default is NULL, and the algorithm starts with the intercepts being the quantiles of response variable and other coefficients being zeros.}
}
\value{
returns a matrix of estimated coefficients in the sparse matrix format. 
Each column corresponds to a lambda value, and is of length (ntau*(p+1)) 
which can be restructured to a coefficient matrix for each tau and each covariate. 
Returned values also include the sequence of lambda, the null deviance, 
values of penalized loss, and unpenalized loss across the sequence of lambda. 
\item{beta}{The estimated coefficients for all taus and a sequence of lambdas, stored in sparse matrix format, where each column corresponds to a lambda.}
\item{lambda}{The sequence of lambdas.}
\item{null.dev}{The null deviance.}
\item{pen.loss}{The value of penalized loss for each lambda.}
\item{loss}{The value of unpenalized loss for each lambda.}
\item{index.nonzero.beta}{Indices stored in a p*nlambda matrix, indicating if the coefficient is zero.}
\item{n.nonzero.beta}{The number of nonzero coefficients for each lambda.}
}
\description{
Uses the group lasso penalty across the quantiles to provide consistent selection across all, Q, modeled quantiles. Let \eqn{\beta^q}
be the coefficients for the $q$th quantiles, \eqn{\beta_j} be the Q-dimensional vector of the jth coefficient for each quantile, and
\eqn{\rho_\tau(u)} is the quantile loss function. The method minimizes
\deqn{\sum_{q=1}^Q \frac{1}{n} \sum_{i=1}^n \rho_\tau(y_i-x_i^\top\beta^q) + \lambda \sum_{j=1}^p\sqrt{Q} ||\beta_j||_2  .}
}
\examples{
n<- 200
p<- 20
X<- matrix(rnorm(n*p),n,p)
y<- -2+X[,1]+0.5*X[,2]-X[,3]-0.5*X[,7]+X[,8]-0.2*X[,9]+rt(n,2)
taus <- seq(0.1, 0.9, 0.2)
fit<- rq.gq.pen(X, y, taus)
matrix(fit$beta[,13], p+1, length(taus), byrow=TRUE)


}
