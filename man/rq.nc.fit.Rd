% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mainFunctions.R
\name{rq.nc.fit}
\alias{rq.nc.fit}
\title{Non-convex penalized quantile regression}
\usage{
rq.nc.fit(
  x,
  y,
  tau = 0.5,
  lambda = NULL,
  weights = NULL,
  intercept = TRUE,
  penalty = "SCAD",
  a = 3.7,
  iterations = 1,
  converge_criteria = 1e-06,
  alg = "LP",
  penVars = NULL,
  internal = FALSE,
  ...
)
}
\arguments{
\item{x}{Matrix of predictors.}

\item{y}{Vector of response values.}

\item{tau}{Conditional quantile being modelled.}

\item{lambda}{Vector of lambdas. Default is for lambdas to be automatically generated.}

\item{weights}{Weights for the objective function.}

\item{intercept}{Whether model should include an intercept. Constant does not need to be included in "x".}

\item{penalty}{Type of penalty: "LASSO", "SCAD" or "MCP".}

\item{a}{Additional tuning parameter for SCAD and MCP}

\item{iterations}{Number of iterations to be done for iterative LLA algorithm.}

\item{converge_criteria}{Difference in betas from iteration process that would satisfy convergence.}

\item{alg}{Defaults for small p to linear programming (LP), see Wang, Wu and Li (2012) for details. QICD is no longer available.}

\item{penVars}{Variables that should be penalized. With default value of NULL all variables are penalized.}

\item{internal}{Whether call to this function has been made internally or not.}

\item{...}{Additional items to be sent to rq.lasso.fit.}
}
\value{
Returns the following:
\describe{
\item{coefficients}{Coefficients from the penalized model.}
\item{PenRho}{Penalized objective function value.  If scalex=TRUE then this is the value for the scaled version of x.}
\item{residuals}{ Residuals from the model.}
\item{rho}{ Objective function evaluation without the penalty.}
\item{coefficients}{ Coefficients from the penalized model.} 
\item{tau}{ Conditional quantile being modeled.}
\item{n}{ Sample size.}  
\item{penalty}{ Penalty used, SCAD or MCP.} 
\item{penalty}{Penalty selected.}
}
}
\description{
Warning: this function is no longer exported. Produces penalized quantile regression models for a range of lambdas and penalty of choice. If lambda is unselected than an iterative algorithm is used to 
find a maximum lambda such that the penalty is large enough to produce an intercept only model. Then range of lambdas goes from the maximum lambda found to "eps" on the 
log scale. Local linear approximation approach used by Wang, Wu and Li to extend LLA as proposed by Zou and Li (2008) to the quantile regression setting.
}
\examples{
\dontrun{
x <- matrix(rnorm(800),nrow=100)
y <- 1 + x[,1] - 3*x[,5] + rnorm(100)
scadModel <- rq.nc.fit(x,y,lambda=1)
}
}
\references{
\itemize{
\item Wang, L., Wu, Y. and Li, R. (2012). Quantile regression of analyzing heterogeneity in ultra-high dimension. \emph{J. Am. Statist. Ass}, \bold{107}, 214--222.
\item Wu, Y. and Liu, Y. (2009). Variable selection in quantile regression. \emph{Statistica Sinica}, \bold{19}, 801--817.
\item Zou, H. and Li, R. (2008). One-step sparse estimates in nonconcave penalized likelihood models. \emph{Ann. Statist.}, \bold{36}, 1509--1533.
\item Peng, B. and Wang, L. (2015). An iterative coordinate-descent algorithm for high-dimensional nonconvex penalized quantile regression. \emph{J. Comp. Graph.}, \bold{24}, 676--694.
}
}
\author{
Ben Sherwood, \email{ben.sherwood@ku.edu} and Adam Maidman.
}
\keyword{internal}
